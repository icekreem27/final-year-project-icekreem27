[
    {
        "question": "What is the topic of the research project Professor Eric Atwell is discussing?",
        "answer": "The research project is about looking into the use of chatbots in higher education."
    },
    {
        "question": "What misconception does the speaker address about chatbots?",
        "answer": "The misconception that chatbots are simply a back-and-forth conversation between a person and a computer."
    },
    {
        "question": "What is the lecturer emphasizing in terms of keeping track of other things in the lecture?",
        "answer": "The lecturer is emphasizing the importance of having interfaces to various other IT systems in addition to keeping track of other things."
    },
    {
        "question": "Who are the research fellows on the project mentioned in the lecture?",
        "answer": "Noorhan Abbas and Tom Pickard"
    },
    {
        "question": "What is the process at Leeds University for providing feedback at the end of a course?",
        "answer": "At Leeds University, students are sent a questionnaire for every module at the end of the course where they have to answer questions on a scale of 1 to 5 to indicate their level of agreement."
    },
    {
        "question": "Why does the chatbot aim to provide more narrative texts and real details?",
        "answer": "The chatbot aims to provide more narrative texts and real details to understand what people like and don't like in more detail."
    },
    {
        "question": "Where were the chatbots developed and used in universities and research centres?",
        "answer": "The chatbots were developed by commercial companies in Norway and Sweden and then used in universities in the UK, Spain, Croatia, and Cyprus."
    },
    {
        "question": "What are the two problems associated with just having a question and responding with a tick box?",
        "answer": "One problem is that you don't get much useful information out of it."
    },
    {
        "question": "What is a potential issue mentioned in the text regarding students responding to questionnaires?",
        "answer": "Some students may get fed up with having to answer multiple questionnaires with many questions on each."
    },
    {
        "question": "What is the name of the chatbot system discussed in the lecture segment?",
        "answer": "Hubert or Hubert.ai"
    },
    {
        "question": "Which companies have voice-driven chatbots mentioned in the lecture?",
        "answer": "Amazon, Google, and Microsoft"
    },
    {
        "question": "What is the name of the demonstrator developed by Amazon Web Services mentioned in the lecture?",
        "answer": "Ask LU"
    },
    {
        "question": "What is an example of a chatbot mentioned in the lecture that was originally developed for commercial services?",
        "answer": "Cora chatbot from NatWest bank"
    },
    {
        "question": "What realization did universities come to about the adaptability of certain architectures to student services?",
        "answer": "Universities realized that certain architectures could be adapted to many student services."
    },
    {
        "question": "What is the purpose of the Differ system mentioned in the lecture?",
        "answer": "The Differ system helps students to get to know each other before they come to the university, promoting student engagement and a sense of community."
    },
    {
        "question": "What is the purpose of automated grading systems for Python programming in introductory programming courses?",
        "answer": "The purpose of automated grading systems for Python programming in introductory programming courses is to analyze the software and provide English language feedback about what the student did wrong."
    },
    {
        "question": "What additional feature does the Coding Tutor chatbot have compared to traditional grading systems?",
        "answer": "The Coding Tutor chatbot provides feedback to students in English along with giving a mark."
    },
    {
        "question": "Why is building in the background knowledge for a chatbot that mimics a real teacher harder than building the background knowledge for a chatbot that provides simple information like the next lecture schedule?",
        "answer": "Building in the background knowledge for a chatbot that mimics a real teacher is harder because real teachers do more than just answer questions; they also provide additional context and engage in more complex interactions."
    },
    {
        "question": "What is one example of a service that is typically done by access to databases?",
        "answer": "One example of a service that is typically done by access to databases is having a chatbot interface to a database."
    },
    {
        "question": "What was the main use case for the project discussed in the lecture?",
        "answer": "The main use case for the project was getting feedback from students about the course."
    },
    {
        "question": "Which universities were partners in the project mentioned in the lecture?",
        "answer": "University of Granada in Spain, University of Zagreb in Croatia, Centre of Excellence in Cyprus, and University of Leeds in the UK."
    },
    {
        "question": "In which types of courses are chatbots typically taught?",
        "answer": "Most of the courses where chatbots are taught are computing-oriented or business-oriented."
    },
    {
        "question": "What is the topic of Professor Eric Atwell's lecture?",
        "answer": "The topic of Professor Eric Atwell's lecture is chatbots, also known as dialogue systems."
    },
    {
        "question": "What are the two main topics covered in the lecture segment?",
        "answer": "The two main topics covered are an introduction to chatbots and dialogue systems, and properties of human conversation."
    },
    {
        "question": "What are some examples of chatbots mentioned in the lecture?",
        "answer": "ELIZA, PARRY, AIML, ALICE, and Hubert"
    },
    {
        "question": "What are some alternative names for dialogue systems or chatbots?",
        "answer": "Conversational agents, dialogue agents"
    },
    {
        "question": "What term is commonly used to refer to these intelligent agents that are designed to achieve some goal?",
        "answer": "Chatbots"
    },
    {
        "question": "What are some examples of personal assistants on phones or other computing devices mentioned in the lecture?",
        "answer": "SIRI for Apple, Alexa from Amazon, Cortana from Microsoft, Google Assistant"
    },
    {
        "question": "What feature allows you to have a verbal conversation with someone in addition to typing?",
        "answer": "The feature that allows you to have a verbal conversation with someone in addition to typing is available in the system."
    },
    {
        "question": "What are some limitations of smart systems mentioned in the lecture?",
        "answer": "Some limitations of smart systems mentioned in the lecture are that they can struggle to answer certain questions properly and they are aimed at a very general audience rather than specific purposes."
    },
    {
        "question": "What are some features that the speaker mentions Alexa can do?",
        "answer": "The speaker mentions that Alexa can play music, set timers, provide various clock functions, and chat for fun."
    },
    {
        "question": "What are some serious tasks that can be done using Alexa?",
        "answer": "Some serious tasks that can be done using Alexa include booking travel reservations, ordering items, shopping via Amazon, and answering general knowledge questions."
    },
    {
        "question": "Who can individuals with mental health problems talk to for help, according to the lecture?",
        "answer": "Individuals with mental health problems can talk to a clinician, a mental health practitioner, or a chatbot for help."
    },
    {
        "question": "What are the two suggested approaches for improving a chatbot's performance?",
        "answer": "The two suggested approaches are letting the chatbot talk and analyzing the transcript afterwards for diagnosis."
    },
    {
        "question": "What are the potential benefits of chatting conversational agents?",
        "answer": "The potential benefits of chatting conversational agents include providing fun, relaxation, companionship, and potentially therapeutic effects for individuals with mental health problems or feelings of loneliness."
    },
    {
        "question": "What are some examples of tasks that targeted task-based dialogue agents may have in mind?",
        "answer": "Booking flights, booking restaurants, buying things via Amazon"
    },
    {
        "question": "What is one example of a task that a personal assistant could help a student or academic with?",
        "answer": "One example is reminding them of when their coursework is due, such as for the OCOM5204M Data mining and text analytics course at the University of Leeds."
    },
    {
        "question": "What are some examples of areas where chatbots can be used?",
        "answer": "Chatbots can be used for driving a car, turning on the air conditioning, giving robot instructions, giving washing machine instructions, and question answering."
    },
    {
        "question": "What are the two types of chatbot architectures mentioned in the lecture?",
        "answer": "The two types of chatbot architectures mentioned are fact-finding questions and task-oriented questions."
    },
    {
        "question": "What are the two approaches mentioned for developing systems in computational linguistics?",
        "answer": "The two approaches mentioned are rule-based systems and machine learning from a corpus."
    },
    {
        "question": "What is the focus of the research papers discussed in the lecture?",
        "answer": "The research papers focus on word embeddings and scaling to big data."
    },
    {
        "question": "What is the standard term for a numerical vector representation of word meaning derived from a corpus?",
        "answer": "Word embedding"
    },
    {
        "question": "What factors are considered when capturing the meaning of a word in a vector?",
        "answer": "The examples of the word, the context it appears in, and the set of contexts representing meaning."
    },
    {
        "question": "What is the significance of having very large data sets when applying real systems like Google Translate?",
        "answer": "Having very large data sets is important for applying real systems like Google Translate in order to improve accuracy and performance."
    },
    {
        "question": "Who conducted experiments on machine learning algorithms in 2001 to see how they scaled from small to large corpora?",
        "answer": "Michelle Banko and Eric Brill from Microsoft Research"
    },
    {
        "question": "What was the real problem up to this point in building vector representations?",
        "answer": "The real problem up to this point had been it took a lot of processing."
    },
    {
        "question": "Where is AI research reported, according to the lecture?",
        "answer": "AI research is reported in universities and industry research labs such as Google Labs, Microsoft Labs, and Facebook Labs."
    },
    {
        "question": "What is the next step after a research paper is peer reviewed and accepted by other experts?",
        "answer": "The next step is usually presenting it at a conference and writing it up in a conference paper for the proceedings."
    },
    {
        "question": "What is the typical length range for a paper submitted to a conference?",
        "answer": "The typical length range for a paper submitted to a conference is four to eight pages, or possibly slightly longer."
    },
    {
        "question": "Where can one find a list of computational linguistics journals and conferences?",
        "answer": "One can find a list of computational linguistics journals and conferences on the website of the Association for Computational Linguistics."
    },
    {
        "question": "What are some additional events that may take place alongside a major conference like ACL?",
        "answer": "Workshops for special interest groups with smaller collections of papers."
    },
    {
        "question": "Where can you find all the papers related to text analytics?",
        "answer": "All the papers related to text analytics can be found in the ACL Anthology."
    },
    {
        "question": "What is the origin of the word 'corpus'?",
        "answer": "The word 'corpus' is based on the Latin word 'corpus', which means a body."
    },
    {
        "question": "What is the plural form of the word 'corpus' in Latin?",
        "answer": "The plural form of the word 'corpus' in Latin is 'corpora' or 'core-pore-ah'."
    },
    {
        "question": "How is the word 'proceedings' described in terms of singular or plural?",
        "answer": "The word 'proceedings' is described as a sort of singular or plural, as it refers to a conference proceedings listing the papers of the conference which can have many papers in it."
    },
    {
        "question": "Why might a student be asked to read AI research papers according to the lecture?",
        "answer": "One reason is to learn about AI research and find out about current research, such as word embeddings."
    },
    {
        "question": "What is the significance of peer-reviewed research in academia?",
        "answer": "Peer-reviewed research is important because it ensures that the work has been evaluated and approved by other experts in the field before publication, thereby maintaining quality and credibility."
    },
    {
        "question": "What is one suggestion for students who are struggling to come up with a research proposal?",
        "answer": "One suggestion is to find a research paper that you like and use it as a basis for writing a proposal, but maybe focus on a different data set, company, or user group."
    },
    {
        "question": "What are some ways in which research can be related to previous research?",
        "answer": "Research can be related to previous research by changing parameters such as using it for a different language, a different user group, or a different but similar sort of task."
    },
    {
        "question": "What is typically included in the background section of a research proposal?",
        "answer": "The background section of a research proposal usually includes information about what other people have done similar to the proposed research."
    },
    {
        "question": "What is the main purpose of presenting results and conclusions in a research paper?",
        "answer": "The main purpose is to present interesting, new results and the conclusions drawn from these results, which contribute to knowledge and explain why the research is important and worth reading by others."
    },
    {
        "question": "What is one benefit of reading research papers when working on a proposal?",
        "answer": "Reading research papers gives you some good ideas about what a proposal should look like."
    },
    {
        "question": "What is one way to enhance a research proposal according to the lecture?",
        "answer": "One way to enhance a research proposal is to conduct a pilot study or proof of concept study to implement something simple and provide initial results."
    },
    {
        "question": "Who is the author of the paper mentioned in the lecture segment?",
        "answer": "Eric Atwell"
    },
    {
        "question": "Where was the paper on discovery procedure for grammar presented in 1986?",
        "answer": "The paper was presented at the ICAME conference."
    },
    {
        "question": "What methods were used to train the bigram models or Markov models discussed in the lecture?",
        "answer": "The methods used were to take a small corpus of 200,000 words, which was 1/5 of the Lancaster-Oslo-Bergen corpus of a million words."
    },
    {
        "question": "What is the process of selecting words for analysis based on their frequency in the text?",
        "answer": "Choosing words that occur 100 times or more in the text"
    },
    {
        "question": "How were words determined to belong to the same word class in the context of the lecture?",
        "answer": "Words were deemed to belong to the same word class if the context lists of the first word were significantly similar to the context lists of the second word."
    },
    {
        "question": "What is unique about the approach discussed in the lecture regarding learning word embeddings from a corpus?",
        "answer": "The unique aspect is that it is the first corpus linguistics approach to learning word embeddings from a corpus, without using neural networks but relying on basic statistics."
    },
    {
        "question": "What was the limitation in terms of the number of words that the processes at the time could cope with in the OCOM5204M Data mining and text analytics course at the University of Leeds?",
        "answer": "The processes at the time could only cope with 200,000 words."
    },
    {
        "question": "How long did the run take on the University mainframe computer?",
        "answer": "Several weeks"
    },
    {
        "question": "What pairs of words were merged together in the lecture?",
        "answer": "The pairs of words 'in' and 'for', and 'is' and 'was' were merged together in the lecture."
    },
    {
        "question": "Why were 'will,' 'should,' 'could,' 'must,' 'may,' and 'might' all merged into a single word class?",
        "answer": "They were merged on the basis of the immediate lexical context of the words that appeared before and after them in the hundred or more cases."
    },
    {
        "question": "What type of words were predominant among the 175 words mentioned in the lecture segment?",
        "answer": "Functional words were predominant among the 175 words mentioned."
    },
    {
        "question": "How did the ability to evaluate results change by the year 2000, 2001?",
        "answer": "By the year 2000, 2001, it was possible to deal with much bigger data sets."
    },
    {
        "question": "Why did Michelle Banko and Eric Brill have access to very powerful computers at Microsoft Research Labs?",
        "answer": "They had access to very powerful computers at Microsoft Research Labs because the computers there were much better and more powerful than what was available at universities."
    },
    {
        "question": "What was the goal of Banko and Brill's research?",
        "answer": "Banko and Brill wanted to evaluate the performance of different learning methods trained on orders of magnitude more label data."
    },
    {
        "question": "What task did the researchers choose to study the effect of having more data on machine learning?",
        "answer": "The researchers chose confusion set disambiguation as the particular task to study the effect of having more data on machine learning."
    },
    {
        "question": "Can you provide an example of how the word 'weather' can be spelled differently in different contexts?",
        "answer": "The word 'weather' can be spelled as W-E-A-T-H-E-R in one context, like 'it is sunny weather today', or as W-H-E-T-H-E-R in another context, like 'I don't know whether to cry or laugh'."
    },
    {
        "question": "What is the advantage of labelled training data in the context of the problem discussed?",
        "answer": "Labelled training data is essentially free as you can go through a corpus and whenever you come across certain words, the actual class is what is spelt, but the possibilities are the other words as well."
    },
    {
        "question": "What is the correct class to replace 'weather' with in the sentence 'And if you come across the weather is sunny today'?",
        "answer": "The correct class to replace 'weather' with is 'unknown'."
    },
    {
        "question": "What approach did they use to evaluate the classifiers and data sets?",
        "answer": "They evaluated a range of different classifiers on a range of different data set sizes."
    },
    {
        "question": "How does the accuracy of systems improve with more data according to the lecture?",
        "answer": "The more data you get, the better the systems are, and the higher the accuracy."
    },
    {
        "question": "What practical conclusion should text analytics researchers reconsider according to the lecture?",
        "answer": "Text analytics researchers should reconsider the trade-off between spending time and money on algorithm development versus spending it on corpus development."
    },
    {
        "question": "What does the lecturer suggest has a much better effect than tweaking the algorithm?",
        "answer": "Giving more training data"
    },
    {
        "question": "What is being shown in figure one of the results discussed in the lecture?",
        "answer": "Learning curves for confusion set disambiguation"
    },
    {
        "question": "What effect did increasing the amount of words have on the accuracy of the classifiers in the study?",
        "answer": "The accuracy of the classifiers increased as the amount of words increased in the study."
    },
    {
        "question": "Which classifier performed the worst for a small amount of data?",
        "answer": "The Winnow classifier (blue line) performed the worst for a small amount of data."
    },
    {
        "question": "How does the performance of the Winnow classifier change with more data compared to the memory-based classifier?",
        "answer": "The Winnow classifier changes from being the worst classifier to the best classifier with more data, while the memory-based classifier, for a small amount of data, was the best classifier but becomes the worst classifier over time with more data."
    },
    {
        "question": "What is the main factor that determines the performance of a classifier according to the lecture?",
        "answer": "The amount of training data you have is the main factor that determines the performance of a classifier."
    },
    {
        "question": "What is emphasized as crucial for computational linguistics to improve accuracy?",
        "answer": "Having a huge corpus and piling up more and more training data."
    },
    {
        "question": "What is one of the problems mentioned when working with a larger data set in machine learning?",
        "answer": "One of the problems mentioned is that the larger the data set, the larger the model that you're learning."
    },
    {
        "question": "What does the size of the internal model refer to in the context of the Winnow algorithm and the memory-based algorithm?",
        "answer": "The size of the internal model refers to how much processor and memory is needed to store and compute with the model."
    },
    {
        "question": "What happens to the size of memory and processor requirements as the number of words in a corpus increases from one million to 1,000 million words?",
        "answer": "The size of memory and processor requirements also grow as the number of words in a corpus increases from one million to 1,000 million words."
    },
    {
        "question": "What is a limitation that university researchers face when using Sketch Engine?",
        "answer": "University researchers using Sketch Engine are limited to having a million-word corpus."
    },
    {
        "question": "What restrictions are placed on students for coursework exercises in terms of memory and processor?",
        "answer": "Students are restricted to memory and processor for coursework exercises."
    },
    {
        "question": "What is an ensemble in the context of machine learning?",
        "answer": "An ensemble in machine learning is when multiple different algorithms are used together and then a collective decision is made based on the outputs of each algorithm."
    },
    {
        "question": "If you have five classifiers and three of them say the answer is x while two say the answer is y, what would be the final answer according to the method described?",
        "answer": "The final answer would be x, as it is determined by the majority of the classifiers."
    },
    {
        "question": "What is the challenge when dealing with very large corpora in terms of finding the best classifier?",
        "answer": "The challenge is that even with very large corpora, you still don't know in advance which classifier is going to be the best, so you have to try all of them to find the best one."
    },
    {
        "question": "According to the lecture, when is an ensemble generally better than an individual classifier?",
        "answer": "An ensemble is generally better than an individual classifier, unless you have a very large training set and you know which one is best for that large training set."
    },
    {
        "question": "What is one of the strategies mentioned for dealing with cases where there may be more than two possible classes?",
        "answer": "One of the strategies mentioned is called active learning."
    },
    {
        "question": "How can ensemble classifiers help with labeling a large amount of data?",
        "answer": "Ensemble classifiers, trained on a small amount of data, can be used to label a large amount of data by identifying the most uncertain instances based on the disagreement among the classifiers."
    },
    {
        "question": "What is one strategy mentioned in the lecture for reducing the cost of labelling instances in active learning?",
        "answer": "Label only the instances which the classifiers aren't so sure about."
    },
    {
        "question": "When should you choose instances for automatic labelling?",
        "answer": "Choose instances which have the highest probability of being correct."
    },
    {
        "question": "What is one consideration when using an automatic classifier trained on a small data set on a growing data set?",
        "answer": "Most classifiers will give some probability that the label is correct."
    },
    {
        "question": "When can you be quite sure about the classification result in an ensemble of classifiers?",
        "answer": "You can be quite sure about the classification result in an ensemble of classifiers when all of the different classifiers in the ensemble vote for the same class."
    },
    {
        "question": "What is one conclusion that researchers should focus on, according to the lecture?",
        "answer": "Researchers should direct efforts towards increasing the size of annotated training collections and de-emphasise the focus on comparing different learning techniques trained only on a small training corpus, or only on small training corpora."
    },
    {
        "question": "What is the recommended approach for training a classifier for a particular task?",
        "answer": "Collecting a large training corpus and annotating it for the task, then using a classifier or ensemble of classifiers."
    },
    {
        "question": "What did Thomas Mikolov and his group at Google Research Labs find in 2013 regarding dealing with very large corpora of words?",
        "answer": "They found that it's difficult to learn very large word representations in vector space."
    },
    {
        "question": "What was the goal of the researchers in developing a novel model architecture?",
        "answer": "The goal was to compute vector representations of words for very large data sets."
    },
    {
        "question": "What are some drawbacks of using certain vector representations?",
        "answer": "Some drawbacks of using certain vector representations are high complexity, requiring a lot of processor, memory, and time."
    },
    {
        "question": "What are the two methods mentioned for representing the meaning of each word from the corpus?",
        "answer": "Continuous Bag of Words (CBOW) and continuous SKIP-GRAM (or just SKIP-GRAM)"
    },
    {
        "question": "Why were the models discussed in the lecture able to process 1,000 million words?",
        "answer": "The models were able to process 1,000 million words because they have much lower computational complexity than feedforward or recurrent neural networks."
    },
    {
        "question": "What did the students demonstrate with the comprehensive test set?",
        "answer": "The students demonstrated their own methods and other people's methods, showing that other people's methods had very low scores compared to their scores."
    },
    {
        "question": "What does the CBOW model predict based on?",
        "answer": "The CBOW model predicts the current word based on the previous and following contexts."
    },
    {
        "question": "What is the SKIP-GRAM model used for in natural language processing?",
        "answer": "The SKIP-GRAM model predicts the surrounding words given the current word."
    },
    {
        "question": "What is one way to evaluate how good a current word is at predicting its context?",
        "answer": "One way to evaluate how good a current word is at predicting its context is by looking at the word before and after, as well as two words before and after."
    },
    {
        "question": "What are word embeddings used for?",
        "answer": "Word embeddings are used as a way of generating vector representations of the meanings of words."
    },
    {
        "question": "What is the issue with the traditional method of evaluating different versions of word vectors, as mentioned in the lecture?",
        "answer": "The issue with the traditional method is that previous papers typically use a table showing some example words and their most similar words, which may look good but lacks a rigorous evaluation process."
    },
    {
        "question": "What types of relations or questions were included in the comprehensive test set created by Mikolov?",
        "answer": "Five types of semantic relations and nine types of syntactic relations"
    },
    {
        "question": "How many semantic pairs are there in table one?",
        "answer": "Nearly 10,000"
    },
    {
        "question": "What is the condition for a question to be assumed correctly answered using this method?",
        "answer": "The question is assumed to be correctly answered only if the closest word to the vector computed using this method is exactly the same as the correct word in the question."
    },
    {
        "question": "What are some examples of how words can be related to each other?",
        "answer": "Words can be related to each other in terms of being a capital city, currency, or a city in a state."
    },
    {
        "question": "What are the two types of relationships mentioned in the lecture?",
        "answer": "The two types of relationships mentioned are semantic relations and syntactic relations."
    },
    {
        "question": "What is the opposite of 'possibly' according to the lecture?",
        "answer": "The opposite of 'possibly' according to the lecture is 'impossibly'."
    },
    {
        "question": "What was the outcome when they tried out some of the other methods with the very large data sets?",
        "answer": "Most of them didn't do too well."
    },
    {
        "question": "What was the accuracy score achieved by Mikolov's recursive neural network system on semantics?",
        "answer": "8.6%"
    },
    {
        "question": "How well did the SKIP-GRAM model perform for semantic relationships?",
        "answer": "The SKIP-GRAM model got half of the semantic relationships right."
    },
    {
        "question": "How did the neural network language model developed by the researchers differ from previous models?",
        "answer": "The neural network language model developed by the researchers had a much bigger training set, with six billion words, compared to previous models which had up to 1,000 million words."
    },
    {
        "question": "What does using very large training corpora for a neural network model show?",
        "answer": "Using very large training corpora for a neural network model gives better results than using smaller ones."
    },
    {
        "question": "What is the process described for finding the relationship between Italy and Paris?",
        "answer": "Taking the vector for Paris, subtracting the vector from France, and adding on the vector for Italy."
    },
    {
        "question": "According to the lecture, when finding the most similar vector to a given vector, what vector should be the most similar?",
        "answer": "Rome should be the most similar vector."
    },
    {
        "question": "According to the lecture, what is the analogy for Microsoft and Windows with respect to IBM?",
        "answer": "IBM is to Linux"
    },
    {
        "question": "According to the lecture, what is the relationship between Japan and sushi?",
        "answer": "Japan is to sushi as France is to tapas."
    },
    {
        "question": "What is the conclusion regarding training high quality word vectors using simple model architectures?",
        "answer": "The conclusion is that it is possible to train high quality word vectors using simple model architectures, compared to popular neural network models like feedforward and recurrence."
    },
    {
        "question": "According to the lecture, what did Banko and Brill show in relation to machine learning and data?",
        "answer": "Banko and Brill showed that if you give machine learning much more data, it will perform better."
    },
    {
        "question": "Why was SKIP-GRAM considered better in handling larger data sets?",
        "answer": "SKIP-GRAM was considered better because it can cope with much larger data sets."
    },
    {
        "question": "Why will high quality word vectors become an important building block for future NLP applications?",
        "answer": "High quality word vectors will become an important building block for future NLP applications because they can help improve overall percentage scores and benefit the research community."
    },
    {
        "question": "What do most NLP systems work on instead of words?",
        "answer": "Most NLP systems work on vector representations of words extracted using something like word2vec."
    },
    {
        "question": "What is the first step in generating word vectors using the given method?",
        "answer": "Constructing a vocabulary from the training text data"
    },
    {
        "question": "How can the resulting word vector file be used in natural language processing and machine learning applications?",
        "answer": "The resulting word vector file can be used as features in many natural language processing and machine learning applications."
    },
    {
        "question": "What tool can be used to display the most similar words and their distances to a given word in word2vec?",
        "answer": "The tool 'distance' can be used to display the most similar words and their distances to a given word in word2vec."
    },
    {
        "question": "What resources are available on the Google code archive website for training corpora?",
        "answer": "The Google code archive website provides pointers to where you can get large training corpora from various sources, not just Google's own."
    },
    {
        "question": "What is the main topic discussed in the lecture segment?",
        "answer": "The main topic discussed in the lecture segment is about methods and software to learn word embeddings, which are numerical vector representations of word meanings."
    },
    {
        "question": "What is suggested as an interesting project idea in the lecture?",
        "answer": "Reproducing results using current technology in data mining and text analytics, instead of 1986 technology."
    },
    {
        "question": "What is the speaker recommending the audience to do after sharing the main findings?",
        "answer": "The speaker recommends that the audience go away and read the main findings for themselves to get a better understanding and an idea of what a research paper is like."
    },
    {
        "question": "According to the lecture, what did Banko and Brill at Microsoft Research Labs show in their experiments?",
        "answer": "Banko and Brill at Microsoft Research Labs showed that the more data you have, whatever your classifier is, it will get better. More data gives higher accuracy for all classifiers."
    },
    {
        "question": "What are the two different algorithms mentioned by Mikolov and his colleagues for efficient estimation of word representations for very large corpora?",
        "answer": "The two different algorithms mentioned are Continuous Bag of Words and SKIP-GRAM models."
    },
    {
        "question": "What is the focus of the lecture on information extraction?",
        "answer": "The focus of the lecture is on extracting named entities and relations from text."
    },
    {
        "question": "Where is Diana Maynard a researcher?",
        "answer": "Diana Maynard is a researcher at the Natural Language Processing Group at University of Sheffield in the UK."
    },
    {
        "question": "What are the two different approaches to building information extraction systems mentioned in the lecture?",
        "answer": "The two different approaches mentioned are using machine learning and a knowledge engineering approach where experts devise rules."
    },
    {
        "question": "What is information extraction?",
        "answer": "Information extraction is the process of automatically extracting structured information from unstructured text."
    },
    {
        "question": "What is the similarity between named entity recognition and information retrieval?",
        "answer": "Both named entity recognition and information retrieval involve extracting relevant information from a text based on specific criteria, such as identifying named entities or matching keywords."
    },
    {
        "question": "What is an example of information retrieval that you have likely used before?",
        "answer": "A Google search"
    },
    {
        "question": "What is the difference between finding answers to questions and information extraction?",
        "answer": "Finding answers to questions requires reading or analyzing documents to find the answer, while information extraction pulls facts and structured information from a document or set of documents."
    },
    {
        "question": "What does an information extraction system do with the contents of a large text collection?",
        "answer": "An information extraction system pulls out the named entities and the relations between those named entities from the contents of a large text collection."
    },
    {
        "question": "Why would you want to use this method over traditional information retrieval query engines?",
        "answer": "With traditional information retrieval query engines, getting out the facts can be quite difficult."
    },
    {
        "question": "What are some examples of questions that could be answered using data mining and text analytics?",
        "answer": "Examples include finding out where the queen has visited in the last year and identifying places on the East Coast of the United States with cases of West Nile virus."
    },
    {
        "question": "Why is it important to be careful when searching for information about 'Queen'?",
        "answer": "It is important to be careful when searching for information about 'Queen' because there are various other queens you might find, so getting the search terms right is quite difficult."
    },
    {
        "question": "What is the difference between information retrieval and information extraction?",
        "answer": "Information retrieval simply returns documents containing the information, while information extraction goes deeper and returns knowledge at a deeper level."
    },
    {
        "question": "What is one benefit of using information extraction in text analysis?",
        "answer": "One benefit of using information extraction is that it allows you to pull out entities and relations from the text and construct a structured database or knowledge base."
    },
    {
        "question": "Why can the results of information extraction still be valuable even if they are not always entirely accurate?",
        "answer": "The results of information extraction can still be valuable because you can go back to the original text to check them."
    },
    {
        "question": "What is the purpose of using NLP to analyze news stories?",
        "answer": "The purpose is to identify the major events, players, entities, and relationships between them, such as in foreign affairs or business news."
    },
    {
        "question": "In what scientific areas is natural language processing useful for research?",
        "answer": "Natural language processing is useful for research in scientific areas such as medicine, pharmacology, and genomics."
    },
    {
        "question": "What is the purpose of the Health and Safety Information Extraction System (HSE) developed at Sheffield?",
        "answer": "The purpose of HSE is to look at company reports about health and safety."
    },
    {
        "question": "Why does every company, including Leeds University, have to report to a health and safety inspector about health and safety issues?",
        "answer": "Every company, including Leeds University, has to report to a health and safety inspector about health and safety issues to ensure compliance with health and safety regulations."
    },
    {
        "question": "What types of questions might an inspector ask regarding health and safety at Leeds University?",
        "answer": "An inspector might ask about the number of deaths and accidents, inquire about the person responsible for health and safety, and question the measures in place to improve health and safety in the workplace."
    },
    {
        "question": "Why might information retrieval not be particularly helpful if you don't have any system at all?",
        "answer": "Information retrieval might not be particularly helpful if you don't have any system at all because it would only return which documents have information about the query, but the documents could be quite large, so you would still have to read through them."
    },
    {
        "question": "What does HSE do in the context of the lecture?",
        "answer": "HSE identifies sentences about health and safety issues or entities, extracts them, and populates a database with the entities and the relationships between them."
    },
    {
        "question": "What is KIM and what can you do with it?",
        "answer": "KIM stands for Kibbutz Information Management System. It is a system where you can ask queries in the form of English sentences about kibbutz, which are collective cooperative farm communes in Israel."
    },
    {
        "question": "How did they populate the database mentioned in the lecture segment?",
        "answer": "They populated the database by extracting information related to kibbutzes from newspaper stories and entities around kibbutzes."
    },
    {
        "question": "What is the purpose of the interface mentioned in the text?",
        "answer": "The purpose of the interface is to provide a user-friendly way for people to write SQL queries by using English sentence-like or quasi-mathematical patterns."
    },
    {
        "question": "What is the relationship between x, y, kibbutz attack, and z in the given context?",
        "answer": "x is involved in y, where y is an event that contains the name 'kibbutz attack', and y took place in z, where z is a country named Israel."
    },
    {
        "question": "Where did the kibbutz attack mentioned in the lecture take place?",
        "answer": "The kibbutz attack mentioned in the lecture took place in Israel."
    },
    {
        "question": "What is the role of the query language in the information extraction mechanism?",
        "answer": "The query language is not part of the information extraction mechanism; it is the interface to the information extraction database."
    },
    {
        "question": "Why is it beneficial to click on the article and read it when you're not sure about the answer?",
        "answer": "It is beneficial to click on the article and read it when you're not sure about the answer because you can find evidence to support the answer and verify its accuracy."
    },
    {
        "question": "What is the Threat Tracker developed by Alias-i used for?",
        "answer": "The Threat Tracker developed by Alias-i is used for tracking threats within text, not using vision or image processing."
    },
    {
        "question": "What method did the Americans use to help soldiers recognize the terrorists they wanted to catch in Iraq?",
        "answer": "The Americans gave every soldier a pack of cards with a photo of one of the terrorists on the back of each card."
    },
    {
        "question": "Why was Huda Ammash referred to as 'Mrs. Anthrax'?",
        "answer": "Huda Ammash was referred to as 'Mrs. Anthrax' because she was supposed to be developing anthrax, a deadly disease."
    },
    {
        "question": "What was the significance of the '5 of Hearts' in the lecture segment?",
        "answer": "The '5 of Hearts' was the card where her photo was on the back and it was another sort of name for her."
    },
    {
        "question": "What is named entity recognition?",
        "answer": "Named entity recognition is the identification of proper names and other references to entities in text and their classification into a set of categories of interest."
    },
    {
        "question": "What is commonly thought of as information retrieval in today's context?",
        "answer": "Google search or web search"
    },
    {
        "question": "How does the lecturer introduce the comparison in the lecture?",
        "answer": "The lecturer introduces the comparison by mentioning the longer history of information retrieval where you type in some keywords and get the documents you want, and then compares it with database querying using something like SQL."
    },
    {
        "question": "What are the two different models discussed for matching keywords and documents in the lecture?",
        "answer": "The two different models discussed are the Boolean set theoretic model and the weighted vector model."
    },
    {
        "question": "What are some strategies to improve the matching and get more relevant results when using a search tool?",
        "answer": "One strategy is query broadening, which involves expanding or modifying the search query to retrieve more relevant information."
    },
    {
        "question": "How does the lecturer compare database querying with document search or web search?",
        "answer": "The lecturer compares database querying with document search or web search by explaining that in a database, the records are made up into fields, and a simple approach to searching for a particular keyword or string of characters is to look for the string with wild cards before and after in any record, in any field."
    },
    {
        "question": "What is the suggested method for finding the word 'graphics' in a text data record?",
        "answer": "Searching for percent graphics percent, where percent means match anything."
    },
    {
        "question": "What is the purpose of storing information in a structured manner in a database?",
        "answer": "The purpose is to facilitate information extraction, content analysis, and effective retrieval of named entities and keywords."
    },
    {
        "question": "What type of information does the University of Leeds module catalogue contain?",
        "answer": "The University of Leeds module catalogue contains information about what modules are taught, what semester they're in, and other details."
    },
    {
        "question": "How would you find all the modules related to a database, AI, or knowledge base using SQL?",
        "answer": "You would have to write a SQL query that joins the tables containing module information with the tables containing information about terms related to database, AI, or knowledge base."
    },
    {
        "question": "What SQL query would you use to select distinct modules that have a term value of either database, AI, or knowledge base?",
        "answer": "SELECT DISTINCT m FROM module WHERE term_value IN ('database', 'AI', 'knowledge base');"
    },
    {
        "question": "Why can't we simply change the ORs to ANDs in this context?",
        "answer": "Changing the ORs to ANDs would imply that a T-value has to be both 'database' and 'AI' at the same time, which is not possible because a T-value can only have one value."
    },
    {
        "question": "Can a system be both database and AI at the same time according to the lecture?",
        "answer": "No, according to the lecture, a system cannot be both database and AI at the same time."
    },
    {
        "question": "What is the approach mentioned in the lecture for finding records with multiple keywords in a database?",
        "answer": "The approach mentioned is to have two T's, T1 and T2, specify when T1 value is database and T2 value is AI, and then find all the records or fields containing T1 and T2."
    },
    {
        "question": "Why isn't database querying using SQL a sensible way for text analytics?",
        "answer": "It gets much more complicated for 'and' than it is for 'or'."
    },
    {
        "question": "Why is standard SQL not suitable for information retrieval with multiple keywords?",
        "answer": "Standard SQL is not suitable for information retrieval with multiple keywords because in information retrieval, you typically have several keywords and you want to find all the documents which have all of them, not just a document which is any one of them. This requires a non-database structure, making it unsuitable for standard SQL."
    },
    {
        "question": "What is the standard indexing method for information retrieval systems?",
        "answer": "The standard indexing method for information retrieval systems involves assigning to each word the number of documents it appears in."
    },
    {
        "question": "What is the basic idea of an inverted file?",
        "answer": "The basic idea of an inverted file is to start off with a number of documents where each document contains specific terms, creating an index of terms to documents."
    },
    {
        "question": "What is the notion of inverting in the context of term-document relationships?",
        "answer": "The notion of inverting refers to having a list of documents that each term contains, rather than a list of terms in each document."
    },
    {
        "question": "What is the first step after obtaining a set of documents for information retrieval?",
        "answer": "The first step is to perform pre-processing to extract a dictionary of all the words that are in all the documents and determine which documents each word came from."
    },
    {
        "question": "What information does the dictionary provided in the lecture contain for each term?",
        "answer": "The dictionary contains the term and the number of times it occurs, along with the index where it is located in the postings file."
    },
    {
        "question": "What is the term being used as an example in the lecture segment?",
        "answer": "The term being used as an example is 'a'."
    },
    {
        "question": "How many times does the word 'and' appear starting at document position number 3?",
        "answer": "The word 'and' appears three times starting at document position number 3."
    },
    {
        "question": "Which documents contain the values three, four, and five as mentioned in the lecture?",
        "answer": "Documents 1, 2, and 3 contain the values three, four, and five respectively."
    },
    {
        "question": "Who is Tom Pickard and what is the main focus of his research at the University of Leeds?",
        "answer": "Tom Pickard is a research fellow at the University of Leeds in the School of Computing. The main focus of his research at the moment is a project called the EDUBOTS project, which is an EU-funded project looking at chatbots and conversational AI in higher education."
    },
    {
        "question": "What is the focus of using chatbots in universities according to the lecture?",
        "answer": "The focus is on how chatbots can help teachers, students, and support staff deliver high-quality teaching and experiences for students."
    },
    {
        "question": "What is the Sketch Engine web tool used for?",
        "answer": "The Sketch Engine web tool is used for text analytics and corpus linguistics research."
    },
    {
        "question": "What is the WebBootCaT tool within Sketch Engine used for?",
        "answer": "The WebBootCaT tool within Sketch Engine is used to collect a corpus of text data from the web for analysis."
    },
    {
        "question": "What is the purpose of the Leeds Internet Corpora?",
        "answer": "To collect very large corpuses or corpora."
    },
    {
        "question": "Who founded Sketch Engine?",
        "answer": "Adam Kilgarriff"
    },
    {
        "question": "What is a concordance?",
        "answer": "A concordance is an example of a particular word or lemma or phrase that appears repeatedly in the corpus, and it shows you some examples of its use in context."
    },
    {
        "question": "What does a distributional thesaurus show in terms of comparing the concordance of a word with other words?",
        "answer": "A distributional thesaurus shows comparing the concordance of this word with the concordance of other words or other words have got similar concordances."
    },
    {
        "question": "What is WebBootCaT and how can it be used?",
        "answer": "WebBootCaT is a special tool for creating a specialised corpus of your own choice from the web. It allows you to line up a word and its translation in various examples."
    },
    {
        "question": "What is one method mentioned in the lecture for identifying specialist terms in a corpus?",
        "answer": "Terminology extraction"
    },
    {
        "question": "What is the purpose of a word sketch for a specific word like 'catch'?",
        "answer": "The purpose of a word sketch is to show what sorts of words appear before and after the specific word, in order to understand its meanings and collocational behavior."
    },
    {
        "question": "What is one of the benefits of using Sketch Engine for analyzing languages other than English?",
        "answer": "One of the benefits is being able to find out what sorts of words come before a particular word or what patterns it appears in for languages like Arabic and Chinese."
    },
    {
        "question": "What is the purpose of the Gigaword corpus within Sketch Engine?",
        "answer": "The purpose of the Gigaword corpus within Sketch Engine is to provide a billion words of Chinese collected from the web using WebBootCaT."
    },
    {
        "question": "How can examining examples of a word or phrase from a corpus help in figuring out its meaning?",
        "answer": "Examining examples of a word or phrase from a corpus can help in figuring out its meaning by providing context and usage patterns."
    },
    {
        "question": "What do the idioms 'Caught with your pants down' and 'Caught red-handed' mean?",
        "answer": "Both idioms mean being caught in a compromising situation."
    },
    {
        "question": "According to the lecture, why are coffee and tea considered to mean similar things?",
        "answer": "Coffee and tea are considered to mean similar things because they come in similar patterns."
    },
    {
        "question": "What is an example given to demonstrate that 'vegetable' apparently means the same as 'tea'?",
        "answer": "The example given is that you can have a 'tea cup' and a 'vegetable cup', which shows that 'vegetable' and 'tea' are interchangeable in this context."
    },
    {
        "question": "What is an example of a tool mentioned in the lecture for examining English and Chinese translations?",
        "answer": "Opus 2 within Sketch Engine"
    },
    {
        "question": "What functionality does WebBootCaT provide for creating a corpus from a web page?",
        "answer": "WebBootCaT allows you to create a corpus from a web page."
    },
    {
        "question": "What are seed words used for when creating a corpus?",
        "answer": "Seed words are words or phrases that are thought to be typical of the topic area being studied."
    },
    {
        "question": "What is the purpose of terminology extraction?",
        "answer": "Terminology extraction compares the words in a given corpus against a standard English corpus to find words that are more frequent in the given corpus."
    },
    {
        "question": "What is the purpose of extracting word lists in Sketch Engine?",
        "answer": "The purpose of extracting word lists in Sketch Engine is to identify words that are particularly frequent in a given corpus."
    },
    {
        "question": "Why is it important to compare the frequency of words in your corpus to a standard corpus?",
        "answer": "It is important to compare the frequency of words in your corpus to a standard corpus to understand how frequent the words are in your corpus compared to a standard baseline."
    },
    {
        "question": "What are some ways to analyze text data besides using terminology?",
        "answer": "Some ways to analyze text data besides using terminology are getting word frequency lists, identifying multi-word expressions, examining collocations, and comparing word sketches."
    },
    {
        "question": "Can you explain the difference between the words 'little' and 'small' in terms of collocations?",
        "answer": "Although 'little' and 'small' may seem to mean the same thing, there are certain collocations with 'little' that do not come with 'small' and vice versa."
    },
    {
        "question": "What can you do within Sketch Engine to analyze a corpus?",
        "answer": "You can do part-of-speech tagging, marking each word as a noun, verb, adjective, or other."
    },
    {
        "question": "What is lemmatization and how can it be applied to languages other than English?",
        "answer": "Lemmatization involves reducing words to their base or root form. For example, 'dogs' can be lemmatized to 'dog' and the plural 's'. This technique can be applied not just for English, but for other languages as well."
    },
    {
        "question": "What tool is mentioned in the lecture for corpus analysis?",
        "answer": "Sketch Engine"
    },
    {
        "question": "What happens when the speaker clicks on a certain element?",
        "answer": "It opens up a web browser page."
    },
    {
        "question": "What is the necessary step to ensure a successful connection according to the lecture?",
        "answer": "The necessary step is to make sure that you connect via the VPN."
    },
    {
        "question": "What are some of the features of Sketch Engine mentioned in the lecture?",
        "answer": "Sketch Engine has lots of very large corpora for Arabic, Chinese, Japanese, and most languages, and it covers a lot of different languages and scripts."
    },
    {
        "question": "What is mentioned as an advantage of the system discussed in the lecture for handling languages like Arabic and Chinese?",
        "answer": "The system could handle languages like Arabic and Chinese even though they don't use the same alphabet as English."
    },
    {
        "question": "What options are available for accessing Sketch Engine according to the lecture?",
        "answer": "According to the lecture, options for accessing Sketch Engine include a 30-day free trial license or having your company pay for it."
    },
    {
        "question": "What type of login does the speaker prefer in the given context?",
        "answer": "The speaker prefers the institutional login over the standard login."
    },
    {
        "question": "What date is the institution scheduled to close down according to the lecturer?",
        "answer": "June 25, 2022"
    },
    {
        "question": "What field is the speaker collecting a corpus in?",
        "answer": "Data mining"
    },
    {
        "question": "What is the language of the corpora being discussed in the lecture?",
        "answer": "The language of the corpora being discussed in the lecture is English."
    },
    {
        "question": "What are the two options mentioned for obtaining text for analysis in the lecture?",
        "answer": "The two options mentioned are uploading your own corpus or finding text on the web."
    },
    {
        "question": "What folder name is being used by default in the given context?",
        "answer": "Web1"
    },
    {
        "question": "What does the lecturer mean by 'web search' in the context of data mining?",
        "answer": "The lecturer means giving search terms related to data mining to a web search engine, which then finds web pages matching those terms and downloads the text."
    },
    {
        "question": "According to the text, how many words or phrases are recommended to choose?",
        "answer": "At least three words or phrases"
    },
    {
        "question": "What is the reason the instructor blacked out the Go before starting?",
        "answer": "The instructor blacked out the Go before starting because they couldn't start without doing at least that."
    },
    {
        "question": "What is the first web page that the search engine matched the search terms to in the given lecture segment?",
        "answer": "waikato.ac.nz.weka"
    },
    {
        "question": "What is the speaker's decision regarding the selection of items mentioned in the text?",
        "answer": "The speaker decides not to deselect any items and chooses to collect all of them."
    },
    {
        "question": "What is meant by 'boilerplate' in the context of web pages?",
        "answer": "In the context of web pages, 'boilerplate' refers to elements such as headings, contact information, links to other web pages, and other non-essential content that is typically removed during extraction."
    },
    {
        "question": "What is the speaker discussing in the given text?",
        "answer": "The speaker is discussing the process of extracting text related to data mining from web pages, which may take some time if there are many search terms or web pages."
    },
    {
        "question": "How many tokens and words were collected in the corpus mentioned in the lecture?",
        "answer": "29,000 tokens and 24,000 words were collected in the corpus."
    },
    {
        "question": "What can be done in Manage Corpus to modify the corpus?",
        "answer": "In Manage Corpus, the corpus can be made bigger and various other things can be done with it."
    },
    {
        "question": "What is the default reference corpus used for key words extraction in the lecture?",
        "answer": "The default reference corpus used for key words extraction is the English Web 2020, or enTenTen."
    },
    {
        "question": "What is the size of the Brown Family corpus mentioned in the lecture?",
        "answer": "One million words"
    },
    {
        "question": "What is the lecturer comparing in terms of frequency in the given text?",
        "answer": "The lecturer is comparing the frequency of words or phrases in a new data mining corpus to the Brown corpus in American and British English from different time periods."
    },
    {
        "question": "What advice does the lecturer give regarding the unfamiliar words mentioned in the text?",
        "answer": "The lecturer advises the audience to look up the unfamiliar words mentioned in the text to figure out their meanings."
    },
    {
        "question": "Why is it important to choose a large corpus as your reference corpus in data mining?",
        "answer": "Choosing a large corpus as the reference corpus is important in data mining because rare words that may not occur frequently in a small corpus can be statistically significant and provide valuable insights."
    },
    {
        "question": "What is the purpose of optimizing the process to work faster?",
        "answer": "The purpose of optimizing the process is to make it work faster."
    },
    {
        "question": "What type of terms are considered good indicators of a specialist domain?",
        "answer": "Multi-word terms"
    },
    {
        "question": "What is Leeds Internet Corpora and how does it compare to Sketch Engine?",
        "answer": "Leeds Internet Corpora is a tool that allows users to query corpora in a similar way to Sketch Engine and obtain a concordance."
    },
    {
        "question": "What is the real reason for looking at the web page mentioned in the text?",
        "answer": "The real reason for looking at the web page is it has some information on open source development of large corpora."
    },
    {
        "question": "How many keywords should you typically collect when building a very large corpus of words from the web?",
        "answer": "About 500 keywords"
    },
    {
        "question": "What type of words are mentioned in the given segment of the lecture?",
        "answer": "Fairly frequent words that are not function words like 'the' and 'and', but typical words like 'picture', 'extent', 'raised', and so on."
    },
    {
        "question": "How does the process of generating queries using WebBootCaT work?",
        "answer": "The process involves taking combinations of words from a list of 500 words, selecting four words at a time to create a query, sending these queries to the search engine, and receiving the results."
    },
    {
        "question": "What does WebBootCaT do after downloading the URLs produced by the search engine?",
        "answer": "WebBootCaT does some post-processing, extracts the text, and gets rid of the unwanted content."
    },
    {
        "question": "What can you do with the frequency lists obtained from corpora?",
        "answer": "You can check to make sure that the outputs are sensible."
    },
    {
        "question": "What is the Special Interest Group mentioned in the lecture segment?",
        "answer": "The Special Interest Group mentioned in the lecture segment is the Association of the Computational Linguistics Special Interest Group on Web As Corpus."
    },
    {
        "question": "Why is it mentioned that the source of information being discussed is a good one?",
        "answer": "It is mentioned that the source of information is good because they have meetings or conferences pretty much every year or every other year, and you can look at the proceedings containing research papers from all presented on Web As Corpus research."
    },
    {
        "question": "What are some ways to find information about a topic area mentioned in the lecture?",
        "answer": "Some ways to find information about a topic area include using Google, Google Scholar, and looking at the Association of Computational Linguistics Special Interest Group for conference proceedings."
    },
    {
        "question": "What is the purpose of using VPN when accessing the web tool for corpus linguistics?",
        "answer": "The purpose of using VPN when accessing the web tool for corpus linguistics is to ensure secure and private connection to the tool."
    },
    {
        "question": "What is one way you can use a corpus in the context of terminology extraction?",
        "answer": "You can use a corpus to collect your own corpus and then to extract a list of terminology from that corpus."
    },
    {
        "question": "According to the lecture, what is a recommended resource for conducting research in a particular area?",
        "answer": "The ACL Special Interest Group for that area."
    },
    {
        "question": "What does BERT stand for in the context of text understanding?",
        "answer": "BERT stands for Bidirectional Encoder Representations from Transformers."
    },
    {
        "question": "What topic will Professor Eric Atwell be discussing?",
        "answer": "N-gram language modeling"
    },
    {
        "question": "What is the purpose of introducing n-grams in modeling a sequence of words or other things?",
        "answer": "The purpose of introducing n-grams is to model a sequence of words or other things."
    },
    {
        "question": "What is one way to deal with the issue of getting zeros when there are no examples of a word in the training set of a language model?",
        "answer": "One way to deal with this issue is by using what's called smoothing."
    },
    {
        "question": "What are some techniques for improving language models mentioned in the lecture?",
        "answer": "Some techniques mentioned are add-one smoothing, backoff, and combining n-gram models by interpolation."
    },
    {
        "question": "Why do mathematicians prefer probabilities that are in the range 0 to 1?",
        "answer": "Mathematicians prefer probabilities in the range 0 to 1 because they are easier to work with compared to scores of some sort of number."
    },
    {
        "question": "Which collocation is more likely in English for describing strong winds: 'high winds' or 'large winds'?",
        "answer": "'High winds' is more likely in English for describing strong winds."
    },
    {
        "question": "How do we capture the probability of high winds in comparison to large winds?",
        "answer": "By capturing the probability of high winds as being greater than the probability of large winds."
    },
    {
        "question": "Why does '15 minutes' have a higher probability than '15 minuets'?",
        "answer": "Because 'minutes' is more likely than 'minuets'."
    },
    {
        "question": "What is the focus of the lecture on data mining and text analytics online communities and resources?",
        "answer": "The focus of the lecture is on social media specifically for data mining and text analytics professionals."
    },
    {
        "question": "What is one benefit of joining 'social media' communities for data mining text analytics professionals?",
        "answer": "One benefit of joining 'social media' communities is to network, meet others, and share knowledge and resources."
    },
    {
        "question": "Why is it useful to look at others who have developed text analytics applied research projects when trying to think of a research project topic?",
        "answer": "It's useful to look at others who have developed text analytics applied research projects when trying to think of a research project topic to get some ideas and inspiration."
    },
    {
        "question": "What are some examples of general social media platforms mentioned in the lecture?",
        "answer": "Some examples of general social media platforms mentioned in the lecture are Facebook, LinkedIn, and Quora."
    },
    {
        "question": "Who is the lecturer for the module on data mining and text analytics?",
        "answer": "Professor Eric Atwell"
    },
    {
        "question": "Who is the lecturer introducing the students to in the lecture?",
        "answer": "Eric Atwell"
    },
    {
        "question": "Who is the Professor of Artificial Intelligence for Language in the School of Computing at Leeds University?",
        "answer": "Eric Atwell"
    },
    {
        "question": "What are some of the research areas that Eric Atwell is involved in?",
        "answer": "Corpus linguistics, artificial intelligence for language, religious text analytics, Arabic and Islamic corpus linguistics, chat bots, and AI for university education."
    },
    {
        "question": "How many units are there in the overall module?",
        "answer": "There are six units in the overall module."
    },
    {
        "question": "What are the main topics covered in unit one of the course?",
        "answer": "Corpus linguistics, text analytics, and sketch engine"
    },
    {
        "question": "What is the focus of unit three in the lecture?",
        "answer": "Unit three focuses on not just the text but the meanings of words and text, comparing texts in terms of how they mean rather than character strings."
    },
    {
        "question": "What are some examples of text analytics discussed in the lecture?",
        "answer": "The examples include text analytics for machine translation, information extraction, and chat bots for University education."
    },
    {
        "question": "Who developed the system BERT?",
        "answer": "BERT was developed by Google research labs."
    },
    {
        "question": "Who are the authors of the textbook Speech and Language Processing?",
        "answer": "Dan Jurafsky and James Martin"
    },
    {
        "question": "What edition of the book is currently available for purchase online?",
        "answer": "The current edition available for purchase online is the second edition."
    },
    {
        "question": "What is the title of the key textbook on data mining mentioned in the lecture?",
        "answer": "Data Mining: Practical machine learning tools and techniques"
    },
    {
        "question": "Will the lecturer cover the machine learning algorithms available in detail during the course?",
        "answer": "No, the lecturer will not cover the machine learning algorithms available in detail during the course. They suggest referring to the textbook for more details."
    },
    {
        "question": "What is the focus of the module on deep learning?",
        "answer": "The focus of the module on deep learning is on looking at the algorithms."
    },
    {
        "question": "What typically happens after researchers come up with something interesting?",
        "answer": "It is generally published, publicized at a conference, and then the papers appear in the conference proceedings, and they are put on the web for everyone to read."
    },
    {
        "question": "What are the two tests in the course and how are they weighted?",
        "answer": "The two tests in the course are an online test covering units one and two, and a second test covering units one to six. The first test is worth 20% of the marks, while the second test is worth 30%."
    },
    {
        "question": "What is the final task that students are required to complete at the end of the module?",
        "answer": "Students are required to write up and submit a report of a maximum of seven pages long."
    },
    {
        "question": "What is required for the report in this course?",
        "answer": "Developing a research project proposal using data mining and text analytics theory, methods, and technologies for a practical application of the student's choice."
    },
    {
        "question": "What resource can students refer to for guidance on writing research project proposals in the field of engineering and physical sciences?",
        "answer": "Students can refer to the Engineering and Physical Sciences Research Council guidance for writing research project proposals."
    },
    {
        "question": "What are some key components that should be included in a research proposal?",
        "answer": "Some key components that should be included in a research proposal are the research hypothesis, objectives, work plan, and methodology."
    },
    {
        "question": "What are some of the components that EPSRC requires for a research project besides the hypothesis and objectives?",
        "answer": "Besides the hypothesis and objectives, EPSRC also requires the background and work program for a research project."
    },
    {
        "question": "What are some questions that the speaker suggests should be considered to evaluate the contribution and importance of the work being discussed?",
        "answer": "The speaker suggests considering questions such as: What other work is going on that's like this? How is this a contribution to knowledge? What's novel about what you're doing? And how is it important? Is it going to make money for the UK or for your company or something? How is it valued?"
    },
    {
        "question": "What is one key component that should be included in the work plan diagram for AI projects?",
        "answer": "A Gantt chart"
    },
    {
        "question": "What does CRISP-DM stand for and what is its significance in data science?",
        "answer": "CRISP-DM stands for Cross Industry Standard Process for Data Mining. It is a widely-used process model for data mining projects in the field of data science."
    },
    {
        "question": "What is the difference between machine learning and data mining?",
        "answer": "Machine learning is a subset of artificial intelligence that focuses on the development of algorithms to allow computers to learn from and make predictions or decisions based on data. Data mining, on the other hand, is the process of discovering patterns and relationships in large datasets to extract useful information."
    },
    {
        "question": "What is the main focus of the machine learning course mentioned in the lecture segment?",
        "answer": "The main focus of the machine learning course is learning the algorithms for doing various different sorts of machine learning, where you input some data and some classes if it's a classifier."
    },
    {
        "question": "What is the importance of aiming for optimal accuracy in data mining?",
        "answer": "The importance of aiming for optimal accuracy in data mining is to measure how many of the predictions are correct in the test set and how many are incorrect."
    },
    {
        "question": "What is data wrangling in the context of data mining?",
        "answer": "Data wrangling involves taking data from various different sources and getting it into the right format so that machine learning algorithms can work on it."
    },
    {
        "question": "How is data typically represented in a spreadsheet for machine learning purposes?",
        "answer": "Data is typically represented in a spreadsheet with rows representing instances and columns representing features."
    },
    {
        "question": "According to the lecture, what do data analysts typically spend the majority of their time on?",
        "answer": "Data analysts typically spend the majority of their time in the process of data wrangling."
    },
    {
        "question": "In the context of machine learning, what is one of the phases in the CRISP-DM model?",
        "answer": "The modeling bit is one of the phases in the CRISP-DM model."
    },
    {
        "question": "What is the first step in the CRISP-DM process mentioned in the lecture?",
        "answer": "The first step is to understand the objectives and requirements that the customer or business wants."
    },
    {
        "question": "Who is the author of the textbook on speech and language processing mentioned in the lecture?",
        "answer": "Dan Jurafsky and James Martin"
    },
    {
        "question": "What is the first issue in text mining as opposed to data mining?",
        "answer": "The first issue in text mining as opposed to data mining is to do with the format of the data."
    },
    {
        "question": "What is the main difference between data typically used in machine learning and text data?",
        "answer": "Data typically used in machine learning is a sequence of numbers separated by commas in CSV format, while text data is a sequence of characters that are made up of words, sentences, and paragraphs."
    },
    {
        "question": "What is one of the tasks that needs to be done in order to process text for a computer?",
        "answer": "One of the tasks is to tokenise the text or break it into chunks."
    },
    {
        "question": "What are regular expressions used for?",
        "answer": "Regular expressions are a formal language for specifying patterns of text strings."
    },
    {
        "question": "What does putting little w and capital W inside square brackets in a regular expression mean?",
        "answer": "Putting little w and capital W inside square brackets means either little w or big W can be matched."
    },
    {
        "question": "In which operating systems are regular expressions available as part of the command language?",
        "answer": "Linux, Unix, OS X"
    },
    {
        "question": "What does the dash z inside square brackets represent in regular expressions?",
        "answer": "It matches anything in the range a to z, any uppercase letter."
    },
    {
        "question": "What does the notation 'not A to Z' mean in the context of the lecture?",
        "answer": "The notation 'not A to Z' means any character other than an uppercase letter."
    },
    {
        "question": "What is another way of saying a disjunction, or or, in regular expressions?",
        "answer": "A pipe letter or character"
    },
    {
        "question": "What are some examples of patterns that can be matched using regular expressions?",
        "answer": "Examples of patterns that can be matched using regular expressions include adding yours, or mine, or a or b or c, having little g big G in square brackets, roundhog, or little w, capital W oodchuck."
    },
    {
        "question": "What does the question mark symbol represent in regular expressions?",
        "answer": "The question mark symbol in regular expressions represents an optional previous character."
    },
    {
        "question": "What does the regular expression 'o*O*h' match?",
        "answer": "The regular expression 'o*O*h' matches zero or more 'o' characters, followed by zero or more 'O' characters, followed by 'h'."
    },
    {
        "question": "Who are the operators 'star' and 'plus' named after?",
        "answer": "Stephen Kleene"
    },
    {
        "question": "What does the dot operator in regular expressions represent?",
        "answer": "The dot operator in regular expressions represents matching any one character."
    },
    {
        "question": "What does the combination of carat, open brackets, carat, A to Z, and a to z signify in regular expressions?",
        "answer": "The combination signifies the start of a string, where the initial character is not a letter."
    },
    {
        "question": "How do you include a special character like a dot (.) in a pattern?",
        "answer": "You have to put a backslash in front of the special character, like \\."
    },
    {
        "question": "What does the backslash character signify in regular expressions?",
        "answer": "The backslash character in regular expressions means to use the next character literally rather than as a special pattern."
    },
    {
        "question": "What is an example of a task that involves string processing in Python, as mentioned in the lecture?",
        "answer": "Finding all the instances of the word 'the' in a text."
    },
    {
        "question": "Why does the lecturer suggest using open square brackets t, little t, capital T to match the word 'the' at the beginning of a sentence?",
        "answer": "The lecturer suggests using open square brackets t, little t, capital T to match the word 'the' at the beginning of a sentence because the character pattern 't-h-e' will miss out 'the' if it's at the start of a sentence."
    },
    {
        "question": "What is the pattern described in the lecture for matching a letter of the alphabet followed by 't' or 'T', followed by 'h-e', followed by not any other letter of the alphabet?",
        "answer": "The pattern is [a-zA-Z][tT]he[^a-zA-Z]."
    },
    {
        "question": "Why is 'other' ruled out as a possible word in the pattern described?",
        "answer": "'Other' is ruled out because it has the letter 'o' before 'the' and the letter 'r' after 'the', which does not match the pattern being discussed."
    },
    {
        "question": "What are false positives in the context of matching strings?",
        "answer": "False positives are when strings are matched that should not have been matched, such as matching 'other' when looking for 'the'."
    },
    {
        "question": "What is a false positive in the context of the lecture?",
        "answer": "A false positive is when a result is identified as a match, but it is not actually what was desired."
    },
    {
        "question": "Why was the pattern 't-h-e' in lower case considered a false negative?",
        "answer": "The pattern 't-h-e' in lower case was considered a false negative because it didn't capture 'The' at the beginning of a sentence due to the lack of a capital letter."
    },
    {
        "question": "What are false positives and false negatives in the context of classification tasks in data mining and machine learning?",
        "answer": "False positives and false negatives are two types of error that occur in classification tasks, where false positives refer to incorrectly identifying something as belonging to a certain class, and false negatives refer to incorrectly failing to identify something as belonging to a certain class."
    },
    {
        "question": "What is the relationship between accuracy and recall in the context of minimizing false positives?",
        "answer": "Accuracy and recall are antagonistic in the context of minimizing false positives, where increasing accuracy means minimizing false positives while increasing recall may lead to more false positives."
    },
    {
        "question": "What is the importance of regular expressions in text analytics?",
        "answer": "Regular expressions are surprisingly important in text analytics because they are quite good at doing some sort of text processing and can be used to capture real examples, minimizing false negatives."
    },
    {
        "question": "In what situations is machine learning necessary according to the lecture?",
        "answer": "Machine learning is necessary for more sophisticated and harder tasks."
    },
    {
        "question": "How can regular expressions be used in the context of machine learning?",
        "answer": "Regular expressions can be used for pre-processing the data, capturing features for classifiers, capturing generalizations, and deciding on the approach for machine learning (deep-learning or traditional)."
    },
    {
        "question": "What is a common use case for the 'sub' function in regular expressions in Python and Unix commands?",
        "answer": "A common use case for the 'sub' function in regular expressions is to substitute a specific regular expression with something else."
    },
    {
        "question": "What is an example of a regular expression mentioned in the lecture?",
        "answer": "c-o-l-o-u-r"
    },
    {
        "question": "What does the regular expression '[0-9]+' mean?",
        "answer": "It means any sequence of matching patterns where the pattern is a digit."
    },
    {
        "question": "How is the pattern at the bottom, within brackets, being replaced in the given example?",
        "answer": "The pattern in brackets, which is any sequence of 0 to 9, any sequence of digits, is being replaced with open angle bracket, followed by the pattern itself, and then closed angle bracket."
    },
    {
        "question": "What does the pattern 'the, dot, star, er' signify?",
        "answer": "The pattern 'the, dot, star, er' means to match anything followed by 'er'."
    },
    {
        "question": "Why won't the phrase 'the faster they ran the faster we ate' match the pattern being discussed?",
        "answer": "The phrase won't match the pattern because 'ate' has to be the same as 'ran', but in this case, it's not."
    },
    {
        "question": "What is an example of a pattern that can be used to match any single word at the beginning of a line, excluding the word 'volcano'?",
        "answer": "A to Z, a to z, is any sequence of characters which will match any word at all, but in brackets we said we don't want a volcano."
    },
    {
        "question": "What is a sophisticated pattern for matching any sequence of characters other than the word 'volcano'?",
        "answer": "The sophisticated pattern is mentioned in the lecture as an example of matching any sequence of characters other than the word 'volcano'."
    },
    {
        "question": "What is the very famous example of a chat bot mentioned in the lecture?",
        "answer": "ELIZA"
    },
    {
        "question": "According to Rogerian psychotherapy, what is the role of the psychotherapist?",
        "answer": "According to Rogerian psychotherapy, the role of the psychotherapist is to talk to the patient and encourage them to draw out for themselves what their problems are by talking about them."
    },
    {
        "question": "What is a common pattern in psychotherapy sessions described in the lecture?",
        "answer": "The user or patient might say 'I need x' and the psychotherapist replies by asking 'What would it mean to you if you got x?'"
    },
    {
        "question": "How can you encourage someone to talk more about a statement they made?",
        "answer": "Repeat it back at them in a slightly more convoluted way to prompt further discussion."
    },
    {
        "question": "How did the speaker demonstrate the technique of repeating back in the given conversation?",
        "answer": "The speaker changed 'my' to 'your' and 'me' to 'you' while repeating back what the person said."
    },
    {
        "question": "How can you show empathy by repeating back part of what was said using patterns?",
        "answer": "By repeating back part of what was said, such as saying 'I'm sorry to hear you are depressed', using some sort of patterns."
    },
    {
        "question": "What should you say in response to someone who says they are depressed or sad according to the lecture?",
        "answer": "I'm sorry to hear you are depressed or sad."
    },
    {
        "question": "What is the topic of discussion in the lecture by Professor Eric Atwell?",
        "answer": "The topic of discussion in the lecture by Professor Eric Atwell is word embeddings or meanings and vector semantics."
    },
    {
        "question": "Why does the lecturer recommend reading the chapter for more detail?",
        "answer": "The lecturer recommends reading the chapter for more detail because even though the lecture covers a lot of information, it does not cover everything in the chapter."
    },
    {
        "question": "What is a word embedding in natural language processing?",
        "answer": "A word embedding is a term used to represent the word meaning for text analysis, typically a real valued vector that encodes the meaning of a word such that words closer in vector space are similar in meaning."
    },
    {
        "question": "How is word similarity measured in vector semantics?",
        "answer": "Word similarity is measured using the cosine function."
    },
    {
        "question": "What are some ways of making vectors more realistic in text processing?",
        "answer": "Using TFIDF (term frequency divided by document frequency) or pointwise mutual information as an alternative to raw frequency."
    },
    {
        "question": "What is word2vec and what does it allow you to do?",
        "answer": "Word2vec is a deep learning tool that allows you to learn word embeddings from large amounts of text."
    },
    {
        "question": "Why is using a word as a string of characters or an index to a vocabulary list not very satisfactory in n-gram models or text classification models?",
        "answer": "Using a word as a string of characters or an index to a vocabulary list is not very satisfactory because words like 'class' and 'classes' would be considered different due to being separate strings, even though they have related meanings."
    },
    {
        "question": "What is the relationship between wedding and marriage, according to the lecture segment?",
        "answer": "Wedding and marriage have different meanings and therefore have nothing in common in terms of meaning."
    },
    {
        "question": "How can AI be applied in computer vision applications?",
        "answer": "AI can be applied in computer vision applications to distinguish between different objects in images, such as labeling a picture of a dog as D-O-G and a picture of a cat as C-A-T."
    },
    {
        "question": "According to the lecture, what question did linguist Barbara Partee ask back in the 1960s?",
        "answer": "Barbara Partee asked 'what is the meaning of life?'"
    },
    {
        "question": "What is typically used as the label for an image in computer vision classification?",
        "answer": "The label for an image in computer vision classification is typically a character string representing the object in the image, such as 'dog', 'cat', or the name of a person."
    },
    {
        "question": "What issue arises when trying to represent a character string as its meaning?",
        "answer": "Saying a character string-- its meaning is a character string doesn't help very much."
    },
    {
        "question": "What does the Latin word 'Desiderate' mean?",
        "answer": "Desiderate is a Latin word meaning 'things that are desirable.'"
    },
    {
        "question": "What information can you typically find in a dictionary entry for a word?",
        "answer": "In a dictionary entry for a word, you can typically find the spelling of the word, the part of speech it belongs to, and a number of senses or meanings."
    },
    {
        "question": "What is the modern sense of the word 'mouse'?",
        "answer": "A hand-operated device that controls a cursor."
    },
    {
        "question": "According to the text, why is defining the meaning of a word as a sequence of words not very useful?",
        "answer": "Defining the meaning of a word as a sequence of words is not very useful because it may not provide a clear or specific definition, as seen in the example where 'mouse' is defined as 'any of numerous small rodents'."
    },
    {
        "question": "What is the focus of the lecture by Professor Eric Atwell?",
        "answer": "The focus of the lecture by Professor Eric Atwell is on sequence labelling for part of speech tagging and named entity recognition."
    },
    {
        "question": "What is part of speech tagging and named entity recognition in the context of natural language processing?",
        "answer": "Part of speech tagging involves adding to every word in a text its part of speech, while named entity recognition involves labeling entities such as names, things, people, or places."
    },
    {
        "question": "What are libelling words in a sequence of words in a text called?",
        "answer": "Parts of speech"
    },
    {
        "question": "What are categories called that words are divided into in text or speech?",
        "answer": "Categories that words are divided into in text or speech are called parts of speech, word classes, pause, or pause tags."
    },
    {
        "question": "Who was the scholar credited with describing Greek and Latin words and categorising them into different parts of speech?",
        "answer": "Dionysus Thrax of Alexandria"
    },
    {
        "question": "Which languages were described as developing from Greek and Roman, Latin?",
        "answer": "English and other languages"
    },
    {
        "question": "Why are there no adjectives in the list mentioned in the lecture?",
        "answer": "Adjectives were not seen as being as important, which is why they are not included in the list."
    },
    {
        "question": "What are closed class words also known as?",
        "answer": "Function words"
    },
    {
        "question": "Why are pronouns considered fairly fixed and not usually come up with new ones?",
        "answer": "Pronouns are considered fairly fixed because people don't usually come up with new pronouns."
    },
    {
        "question": "What pronoun should be used instead of 'she' or 'he' when referring to a person?",
        "answer": "They"
    },
    {
        "question": "What types of words are almost always considered out-of-vocabulary words in a corpus or test set?",
        "answer": "Content words such as nouns, verbs, adjectives, or adverbs."
    },
    {
        "question": "What are some examples of interjections mentioned in the lecture?",
        "answer": "Examples of interjections mentioned in the lecture include oh, ouch, and uh-huh."
    },
    {
        "question": "In the context of building AI systems for analyzing language, why is it important to be aware of categories like verbs?",
        "answer": "It is important to be aware of categories like verbs when building AI systems for analyzing language because verbs are used to perform actions and convey information about the subject's actions in a sentence."
    },
    {
        "question": "What are the two main categories of nouns mentioned in the lecture?",
        "answer": "The two main categories of nouns mentioned in the lecture are proper nouns and common nouns."
    },
    {
        "question": "What types of words are considered open class in language?",
        "answer": "Adjectives, adverbs, interjections, and verbs are considered open class in language."
    },
    {
        "question": "What are some examples of closed class words mentioned in the lecture?",
        "answer": "Some examples of closed class words mentioned in the lecture are determiners, conjunctions, pronouns, prepositions, and particles."
    },
    {
        "question": "What is the relationship between numbers and letters in ordinary text?",
        "answer": "Numbers are sort of halfway between letters and symbols because there is only a set number of digits in a specific sequence in English."
    },
    {
        "question": "What is meant by the term 'closed class' in the context of generating numbers?",
        "answer": "In the context of generating numbers, a closed class refers to a set of individual components, such as 100, 20, 2, that can be combined in a structured way to form numbers."
    },
    {
        "question": "What is part of speech tagging and why is it made difficult?",
        "answer": "Part of speech tagging involves assigning a speech, or tag, to each word in the text. It is made difficult because words can have more than one part of speech."
    },
    {
        "question": "What is the example used to explain the concept of a word having different meanings?",
        "answer": "The example used is 'book', which can refer to a physical object (noun) or to reserving a service (verb)."
    },
    {
        "question": "Why is it more difficult to determine the meaning of a word in context compared to simply looking it up in a dictionary?",
        "answer": "It is more difficult because a word in a dictionary may have two or more parts of speech, and the context of the sentence needs to be considered to determine the correct meaning in that particular context."
    },
    {
        "question": "What does mapping a sequence of words onto a sequence of part of speech tags involve?",
        "answer": "Mapping a sequence of words onto a sequence of part of speech tags involves assigning each word in the sequence a corresponding part of speech tag based on its location within the sequence."
    },
    {
        "question": "What is the purpose of the universal dependencies tag set that researchers are trying to come up with?",
        "answer": "The purpose is to have a tag set that applies to all languages, including open classes like adjective, adverb, noun, verb, and a special one for proper noun."
    },
    {
        "question": "What is the additional class mentioned besides common nouns, proper nouns, and closed classes?",
        "answer": "The additional class mentioned is punctuation."
    },
    {
        "question": "What are the additional symbols that could be present in some texts, according to the lecture?",
        "answer": "In some texts, you could have other symbols like dollar signs or emojis."
    },
    {
        "question": "How does the universal tag set allow for variations in different languages?",
        "answer": "The universal tag set allows for variations in different languages by allowing other tags to be added for particular languages or particular types of text."
    },
    {
        "question": "What is the format of a word and its corresponding tag in Sketch Engine?",
        "answer": "A word followed by a space and then a tag."
    },
    {
        "question": "What is mentioned as examples of tag sets for English in the lecture?",
        "answer": "The Brown Corpus of American English and the Lancaster-Oslo/Bergen corpus of British English"
    },
    {
        "question": "Who developed the International Corpus of English and what was their criticism of the Brown and LOB tag sets?",
        "answer": "Professor Greenbaum at London University developed the International Corpus of English and criticized the Brown and LOB tag sets for not being quite right, so he decided to make it better."
    },
    {
        "question": "What is the significance of the tag set developed at the University of Pennsylvania?",
        "answer": "The tag set developed at the University of Pennsylvania had different labels and variations in the boundaries of the categories compared to other tag sets."
    },
    {
        "question": "What was the purpose of the project called Amalgam mentioned in the lecture?",
        "answer": "The purpose of the project called Amalgam was to work out a way of mapping between different tag sets to merge data sets tagged in different ways."
    },
    {
        "question": "Why is it important for language teachers to know the difference between nouns and verbs?",
        "answer": "It is important for language teachers to know the difference between nouns and verbs because nouns can be used in one way and verbs can be used in another way, and it is useful to know which are the nouns and which are the verbs."
    },
    {
        "question": "What is the first step in working out the grammatical structure of a sentence?",
        "answer": "The first thing you need to do is work out which are the nouns, and which are the verbs, and so on."
    },
    {
        "question": "Why is it important to consider the order of words when translating from Spanish to English in machine translation?",
        "answer": "It is important because in Spanish, a noun may be followed by an adjective, while in English, an adjective typically comes before the noun. Therefore, the order of words must be swapped around during translation."
    },
    {
        "question": "What is one challenge when doing a simple word-to-word mapping for similar languages like Spanish and English?",
        "answer": "One challenge is that you may have to do some reordering for adjectives and nouns."
    },
    {
        "question": "Why are adjectives particularly important in sentiment analysis?",
        "answer": "Adjectives are particularly important in sentiment analysis because they typically convey emotions such as good, happy, nice, bad, and rubbish."
    },
    {
        "question": "Can you provide an example of a word with multiple meanings that are spelled the same?",
        "answer": "Lead is an example of a word with multiple meanings that are spelled the same but have different pronunciations and contexts."
    },
    {
        "question": "What is the difference between the words 'noun' and 'verb'?",
        "answer": "A noun is a person, place, thing, or idea, while a verb is an action or state of being."
    },
    {
        "question": "What percentage of words found in a dictionary are considered to be ambiguous, according to the lecture?",
        "answer": "15%"
    },
    {
        "question": "What percentage of words are considered unambiguous according to the lecture?",
        "answer": "85%"
    },
    {
        "question": "Can you provide examples of the word 'back' being used as an adjective, noun, and verb in a sentence?",
        "answer": "Adjective: 'A small building in the back.' Noun: 'A clear majority of senators back the bill.' Verb: 'Enable the country to buy back debt.'"
    },
    {
        "question": "What part of speech is 'back' in the sentence 'Buy back'?",
        "answer": "Back is a participle in the sentence 'Buy back'."
    },
    {
        "question": "How can you measure the accuracy of a tagger in text analysis?",
        "answer": "You can measure the accuracy of a tagger by counting how many effort words are correctly tagged in a piece of text. Sophisticated models can achieve around 97% accuracy."
    },
    {
        "question": "What percentage of words are considered very difficult to get right?",
        "answer": "About 3% of words"
    },
    {
        "question": "What is the approximate rate of disagreement between two different people when tagging a piece of text?",
        "answer": "About 3% of the words"
    },
    {
        "question": "What is the best performance that can be achieved when humans are asked to solve complex cases?",
        "answer": "The best performance that can be achieved when humans are asked to solve complex cases is the human performance."
    },
    {
        "question": "What is the baseline model and how does it work?",
        "answer": "The baseline model is a simple and fast model that looks up a word in the dictionary. If the word has one tag, it assigns that tag. If the word has multiple tags, it assigns the most frequent tag."
    },
    {
        "question": "According to the lecture, how should unknown words be tagged in order to achieve high accuracy?",
        "answer": "Unknown words should be tagged as nouns to achieve high accuracy."
    },
    {
        "question": "What is the main challenge in part-of-speech tagging research according to the lecture?",
        "answer": "The main challenge is dealing with the 3% of words that are ambiguous."
    },
    {
        "question": "How does a natural language processing system handle ambiguous words with multiple parts of speech?",
        "answer": "It looks up each word in a dictionary and lists the possible parts of speech, then determines the correct one based on context and prior probabilities of the word."
    },
    {
        "question": "What is the main focus when determining the probability of a word being auxiliary, noun, or verb?",
        "answer": "The main focus is on the given word in the dictionary."
    },
    {
        "question": "How can the presence of the word 'the' before 'bill' help determine whether 'bill' is being used as a noun or a verb?",
        "answer": "If the word 'the' is before 'bill', it's almost certainly a noun and not likely to be a verb."
    },
    {
        "question": "What strategy can you use to determine the part of speech of a word that is not in your dictionary?",
        "answer": "You can look at the suffixes or prefixes of the word. For example, a word ending in 'ly' is probably an adjective or adverb."
    },
    {
        "question": "What should you consider in English to determine if a word is a proper noun?",
        "answer": "In English, you could look at the first letter. If the first letter is a capital, then it's probably a proper noun unless it's the first word of a sentence."
    },
    {
        "question": "What is the basis of constraint grammar?",
        "answer": "The basis of constraint grammar is ruling out possibilities based on the context, such as if a certain word appears before, it can rule out that it is a verb."
    },
    {
        "question": "What kind of systems can be developed using hand-crafted, rule-based methods?",
        "answer": "Hand-crafted, rule-based systems can be developed using this method."
    },
    {
        "question": "What is one potential challenge of getting a PhD by developing a rule-based system for an obscure language?",
        "answer": "One potential challenge is that it requires someone to spend a lot of time doing linguistic research to work on defining the rules and gradually adding them."
    },
    {
        "question": "What are some examples of supervised machine-learning algorithms commonly used in AI?",
        "answer": "Some examples of supervised machine-learning algorithms commonly used in AI are Hidden Markov models, Engram models, and maximum entropy Markov models."
    },
    {
        "question": "What types of neural network models have been applied to part-of-speech tagging in recent years?",
        "answer": "Neural network models like transformers and large deep-learning models like BERT have been applied to part-of-speech tagging."
    },
    {
        "question": "Why is there still a need to develop a hand-labelled training set even though a tagger can be run?",
        "answer": "There is still a need to develop a hand-labelled training set because the tagger is not perfect and using it alone would result in imperfect training data."
    },
    {
        "question": "What approach was taken to tag the LOB corpus?",
        "answer": "A rule-based system was developed to tag part of the corpus, followed by the application of a Hidden Markov model to improve the tagging, and then the whole corpus was tagged using this approach."
    },
    {
        "question": "What was the end result of going through and proofreading the training set multiple times?",
        "answer": "The end result was a training set that was 100% perfect."
    },
    {
        "question": "What is the current trend in machine learning regarding the use of training sets?",
        "answer": "The current trend in machine learning is to move away from large, hand-labelled training sets and instead use deep learning or neural network models to learn the models themselves and self-improve."
    },
    {
        "question": "What is another task, besides part-of-speech tagging, that the lecturer mentions as a current research area?",
        "answer": "Named entity recognition"
    },
    {
        "question": "What is a named entity and what are some examples of named entities?",
        "answer": "A named entity is a tag like person, location, organisation, or geopolitical entity, place. Examples of named entities include New York and New York City."
    },
    {
        "question": "What is the additional complexity involved in identifying proper names compared to part-of-speech tagging?",
        "answer": "The additional complexity in identifying proper names compared to part-of-speech tagging is finding the span of text that constitutes the proper name and then tagging the type of this entity."
    },
    {
        "question": "What are the two steps mentioned for identifying entities in a given text?",
        "answer": "The two steps are: identifying which words are the entity and determining the type of the entity."
    },
    {
        "question": "What is the difference between the labelling of 'United Airlines' and 'Tim Wagner' as mentioned in the lecture segment?",
        "answer": "The difference is that 'United Airlines' is an organisation and 'Tim Wagner' is a person."
    },
    {
        "question": "What are the two tasks mentioned in the lecture that are difficult?",
        "answer": "Segmentation and libelling task"
    },
    {
        "question": "What is the significance of York Street in relation to New York?",
        "answer": "York Street goes from Leeds to York, and a new street was built next to it which is called the new York Street. Therefore, in this case, New York is not an entity, but it is York that is the entity."
    },
    {
        "question": "What is a common application of sentiment analysis mentioned in the lecture?",
        "answer": "A common application of sentiment analysis mentioned in the lecture is identifying the company, product, or name of the person being talked about."
    },
    {
        "question": "What is the importance of identifying entities in question answering and information extraction?",
        "answer": "Identifying entities in question answering and information extraction helps in finding the answer to a question and understanding the relationships between entities in a text."
    },
    {
        "question": "What is the special case mentioned in part-of-speech tagging when it comes to segmentation?",
        "answer": "The special case mentioned is when there is a space in a phrase like New York, which should be labeled as one proper name instead of two."
    },
    {
        "question": "What is the problem of ambiguity mentioned in the lecture?",
        "answer": "The problem of ambiguity mentioned in the lecture is that some words, like 'Washington', can have multiple meanings such as being a person, an organization, a location, or a geopolitical entity."
    },
    {
        "question": "What is one way to handle the issue of using part-of-speech tagging algorithms on multiple words?",
        "answer": "One way to handle the issue is through BIO tagging."
    },
    {
        "question": "What is meant by BIO tagging in the context of tagging entities?",
        "answer": "BIO tagging involves assigning tags like person, organisation, location, etc., and indicating whether the entity begins, is inside, or is something else in the text."
    },
    {
        "question": "Why is the idea of 'Jane' being ambiguous between 'begin person' and 'inside person' important in the context of the lecture?",
        "answer": "The idea of 'Jane' being ambiguous between 'begin person' and 'inside person' is important because typically 'begin person' will only occur after another, and it will never occur after an inside tag."
    },
    {
        "question": "What is the purpose of B token and I token in tagging?",
        "answer": "B token begins a span and I token is inside a span for different tags in tagging."
    },
    {
        "question": "How many total tags are there when there are n begin tanks and n other tags?",
        "answer": "There are 2n plus 1 total tags."
    },
    {
        "question": "What are some variants on the BIO tagging system?",
        "answer": "Some variants on the BIO tagging system include adding extra tags like begin, inside, and other; or using just inside and other tags (I tags and O tags); or including begin, inside, and end tags."
    },
    {
        "question": "What is the purpose of using B-I-O tags in the context of entity recognition?",
        "answer": "The purpose of using B-I-O tags in entity recognition is to mark the beginning (B), inside (I), and end (O) of entities in text."
    },
    {
        "question": "What are some standard algorithms used for supervised machine learning in named entity recognition?",
        "answer": "Hidden Markov models"
    },
    {
        "question": "What are two different sorts of tagging mentioned in the lecture?",
        "answer": "Rule-based systems for named entity extraction and other sorts of tagging"
    },
    {
        "question": "What preprocessing step is suggested before performing information extraction or machine translation on a text?",
        "answer": "Labeling each word with its part of speech and each entity with its entity category."
    },
    {
        "question": "How can the additional features added in the lecture be utilized in machine learning applications?",
        "answer": "The additional features added in the lecture can be used later on in machine learning applications like information extraction."
    },
    {
        "question": "Who is the professor discussing text classification in the lecture?",
        "answer": "Professor Eric Atwell"
    },
    {
        "question": "What distinguishes text classification from other types of classification?",
        "answer": "The difference with text classification is that the data being classified is text."
    },
    {
        "question": "Which classifier is the lecturer focusing on in this segment of the lecture?",
        "answer": "The Naive Bayes classifier."
    },
    {
        "question": "What is one example of how the underlying model can be applied in learning?",
        "answer": "One example is sentiment analysis."
    },
    {
        "question": "What is the focus of the lecture when the speaker mentions sentiment classification and Native Bayes?",
        "answer": "The focus is on looking at sentiment classification and how Native Bayes is similar to Markov or N-gram language modeling."
    },
    {
        "question": "What are some measures other than accuracy that can be used to evaluate classification models?",
        "answer": "Precision, recall, and F measure are other measures that can be used to evaluate classification models."
    },
    {
        "question": "What ethical issue can arise when using classification in text analysis?",
        "answer": "An ethical issue that can arise is the reproduction of bias from the training set to the test set."
    },
    {
        "question": "How does Outlook determine if an email is spam?",
        "answer": "Outlook determines if an email is spam based on the words used in the email, without requiring the user to read it."
    },
    {
        "question": "What was a big issue in American history before the existence of Twitter or the internet?",
        "answer": "A big issue in American history before the existence of Twitter or the internet was whether independent states like New York or Florida should join up to become the United States."
    },
    {
        "question": "What method did J. Madison and Hamilton use to persuade people to join the United States?",
        "answer": "They wrote letters or papers."
    },
    {
        "question": "Who were the mathematicians in the 1960s who used Bayesian mathematics to analyze texts and predict the authors of 12 letters?",
        "answer": "Mosteller and Wallace"
    },
    {
        "question": "What is a classic example of text analytics classification mentioned in the lecture?",
        "answer": "Doing text analytics classification back in the 1960s"
    },
    {
        "question": "What is the University of Leeds 2 of 16 medical subject hierarchy used for in medical research?",
        "answer": "The University of Leeds 2 of 16 medical subject hierarchy is used to classify articles according to the MeSH Subject Category Hierarchy in medical research."
    },
    {
        "question": "What are the two main topics discussed in the article?",
        "answer": "The two main topics discussed in the article are blood supply and drug therapy."
    },
    {
        "question": "What university was one of the founding places for a movie review database mentioned in the lecture?",
        "answer": "Leeds University"
    },
    {
        "question": "What are some examples of positive words mentioned in the lecture for sentiment analysis?",
        "answer": "Examples of positive words mentioned in the lecture for sentiment analysis are 'richly', 'great', 'awesome', and 'love'."
    },
    {
        "question": "What is the purpose of sentiment analysis mentioned in the lecture?",
        "answer": "The purpose of sentiment analysis is to determine whether a review is positive or negative based on the count of positive and negative words."
    },
    {
        "question": "What are some common ways for customers to provide feedback on products in the industry?",
        "answer": "Customers can provide feedback on products by giving a review in plain English and a star rating."
    },
    {
        "question": "What are some other applications of analyzing public opinions mentioned in the lecture?",
        "answer": "Some other applications include analyzing consumer confidence, tweets about political candidates during elections, and predicting election outcomes or market trends."
    },
    {
        "question": "What is one way of predicting whether stocks or shares are going to go up or down?",
        "answer": "Analyzing newspaper articles about that stock and seeing if that predicts positive or negative movement."
    },
    {
        "question": "What are some examples of emotions mentioned in the lecture?",
        "answer": "Angry, sad, joyful, fearful"
    },
    {
        "question": "What is sentiment analysis in computational terms primarily concerned with?",
        "answer": "Sentiment analysis in computational terms is primarily concerned with capturing the attitudes of people when they write things, such as whether they like, love, or hate something."
    },
    {
        "question": "What is the focus of sentiment analysis as discussed in the lecture?",
        "answer": "The focus of sentiment analysis is the detection of attitudes, specifically whether the attitude is positive or negative."
    },
    {
        "question": "What are some examples of applications for text classification mentioned in the lecture?",
        "answer": "Some examples of applications for text classification mentioned in the lecture are sentiment analysis (positive or negative) and spam analysis (spam or not spam), many of which are binary."
    },
    {
        "question": "What are some examples of situations where you might need more than two classes in classification?",
        "answer": "Examples include identifying multiple possible offers, determining the language of a text, and identifying the topic of a medical document."
    },
    {
        "question": "What is the input for the classifier mentioned in the lecture segment?",
        "answer": "The input for the classifier is a document and a fixed set of classes that the researcher has decided in advance."
    },
    {
        "question": "What method can be used to determine which class a document belongs to from a set of classes?",
        "answer": "The method to determine which class a document belongs to from a set of classes is not necessarily machine learning. Spam identification, for example, has been around before there were deep learning classifiers."
    },
    {
        "question": "What is a simple solution mentioned in the lecture for identifying spam emails?",
        "answer": "Having rules such as blacklisting email addresses, detecting the presence of dollars, or specific phrases like 'you have been selected.'"
    },
    {
        "question": "What is one alternative to building and maintaining rules for detecting spam?",
        "answer": "One alternative is to do supervised machine learning."
    },
    {
        "question": "Why is it necessary to have a training set labeled by an expert for supervised machine learning?",
        "answer": "It is necessary to have a training set labeled by an expert for supervised machine learning because each instance needs to be labeled in order for the machine learning model to learn and make predictions accurately."
    },
    {
        "question": "What is the purpose of a classifier in the context of document labeling?",
        "answer": "The purpose of a classifier is to determine the class to which a given document belongs based on the labeled documents provided to it."
    },
    {
        "question": "What approach should you take when choosing a classifier in a Python toolkit?",
        "answer": "Try out several different classifiers and see empirically which one is best."
    },
    {
        "question": "What simplifying assumption does the Naive Bayes classifier make about the document?",
        "answer": "The Naive Bayes classifier assumes that the document is just a bag of words."
    },
    {
        "question": "Why is the order of words not important in the bag of words assumption?",
        "answer": "In the bag of words assumption, the order of words is not important because it is treated as a set of words. Each word is counted based on how many times it occurs, regardless of its position in the text."
    },
    {
        "question": "What is the importance of the frequency of words in the context of the lecture?",
        "answer": "The frequency of words is not considered important in this context. What matters is the presence of the words themselves."
    },
    {
        "question": "What is the bag of words representation in text analysis?",
        "answer": "The bag of words representation is essentially a list of words in a document and how many times they occur, but the frequency of words doesn't matter too much - it's just based on whether the word is present or not (frequency of 1 or 0)."
    },
    {
        "question": "What is a Naive Bayes classifier used for?",
        "answer": "A Naive Bayes classifier is used to predict the class based on a particular combination of words, such as sentiment (positive or negative) or categorizations like good or bad."
    },
    {
        "question": "What is Bayes' rule and how is it used in the context of a Naive Bayes classifier?",
        "answer": "Bayes' rule states that the probability of a class given a document is equal to the probability of the document given the class times the probability of the class divided by the probability of the document. In the context of a Naive Bayes classifier, we aim to maximize the probability of a class given a document."
    },
    {
        "question": "What is the objective when finding the most likely class for a particular document using the Bayes equation?",
        "answer": "The objective is to maximize the probability of a document given a class times the probability of a class."
    },
    {
        "question": "What is the approach to finding the most probable class for a document based on the given text?",
        "answer": "To find the most probable class for a document, one must calculate the probability of the document given the class multiplied by the probability of the class for all possible classes, and then choose the class with the highest score."
    },
    {
        "question": "How is a document represented in the context of finding the maximized probability of the set of words in the document given the class?",
        "answer": "The document is represented as a set of features, which are essentially the words in the document."
    },
    {
        "question": "What is the thing that is being calculated in this context?",
        "answer": "The likelihood of a class given the known classes."
    },
    {
        "question": "What is one method mentioned in the text for determining sentiment in a labeled training set?",
        "answer": "Counting the relative frequencies of positive and negative labels in the corpus."
    },
    {
        "question": "Why do we need a very large number of training examples when estimating the likelihood of a word for a particular class?",
        "answer": "We need a very large number of training examples in order to estimate, for each word, how likely it is for a particular class."
    },
    {
        "question": "What is the topic of the lecture by Professor Eric Atwell?",
        "answer": "The topic of the lecture by Professor Eric Atwell is 'CHEAT and NLTK and other platforms for text analytics in Python'."
    },
    {
        "question": "What is the name of the approach used to tackle the Morpho Challenge in computational linguistics?",
        "answer": "The CHEAT approach"
    },
    {
        "question": "Who authored the paper on the Natural Language Toolkit (NLTK)?",
        "answer": "Steven Bird"
    },
    {
        "question": "Is it possible to do computational linguistics or text analytics without any programming?",
        "answer": "Yes, it is possible to do computational linguistics or text analytics without any programming by using tools like Sketch Engine to collect and analyze a corpus."
    },
    {
        "question": "What are some features of Weka toolkit mentioned in the lecture?",
        "answer": "Some features of Weka toolkit mentioned in the lecture include loading in data, running various filters to change its format, choosing from a wide range of classifiers, clustering algorithms, association algorithms, visualization tools, and data analysis tools."
    },
    {
        "question": "Why might researchers need to write code when developing and testing new machine learning algorithms?",
        "answer": "Researchers may need to write code when developing and testing new machine learning algorithms because existing algorithms may not suffice for their specific needs, especially when they are working on something new and innovative."
    },
    {
        "question": "What existing tool in Python is mentioned as an example in the lecture?",
        "answer": "NLTK"
    },
    {
        "question": "What are some examples of existing toolkits mentioned in the lecture that can be used to avoid coding from scratch?",
        "answer": "Some examples of existing toolkits mentioned in the lecture are the Google Code Archive and NLTK."
    },
    {
        "question": "According to the lecture, what is the first thing you should do when you have any experiment or task?",
        "answer": "The first thing you should do when you have any experiment or task is to look at the task and see what's the easiest way of doing it."
    },
    {
        "question": "Why might you not need to code if there is a tool like Sketch Engine available?",
        "answer": "Because tools like Sketch Engine can solve the problem, eliminating the need for coding."
    },
    {
        "question": "What is one example of a tool that can be used for text analytics and computational linguistics in Python?",
        "answer": "Natural Language Toolkit (NLTK)"
    },
    {
        "question": "What is NLTK known for in the context of working with human language data?",
        "answer": "NLTK is known as the leading platform for building Python programs to work with human language data."
    },
    {
        "question": "What is WordNet and how are words grouped in it?",
        "answer": "WordNet is a resource where words are grouped into synsets, which are groups of words that have similar meaning."
    },
    {
        "question": "What are some of the text processing libraries mentioned in the lecture?",
        "answer": "Some of the text processing libraries mentioned are for text classification, text tokenization, stemming, tagging, parsing, and semantic reasoning."
    },
    {
        "question": "What are some ways to access tools outside of NLTK within NLTK?",
        "answer": "There are wrappers for industry strength NLP libraries that allow you to access tools outside of NLTK within NLTK."
    },
    {
        "question": "What are some benefits of signing up to the NLTK discussion forum?",
        "answer": "Some benefits of signing up to the NLTK discussion forum include being able to pose questions and get answers from other people, as well as listening in to see other discussions and getting good ideas for ways of doing things. Additionally, the forum offers a hands-on guide introducing programming fundamentals alongside topics in computational linguistics."
    },
    {
        "question": "Who are the authors of the textbook on introduction to natural language processing using Python?",
        "answer": "Steven Bird and others"
    },
    {
        "question": "What is the focus of the module on Python programming?",
        "answer": "The focus of the module is on theory and underlying methods, assuming that students already have programming skills."
    },
    {
        "question": "What are some additional functionalities that the NLTK provides, besides text analysis?",
        "answer": "The NLTK provides tools for testing classifiers, displaying results, and other functionalities."
    },
    {
        "question": "What is the purpose of the parser mentioned in the lecture segment?",
        "answer": "The purpose of the parser is to work out the grammatical structure of a sentence and come up with an internal data representation."
    },
    {
        "question": "What is the purpose of the Treebank module in natural language processing?",
        "answer": "The Treebank module contains parsed corpora where each sentence has a parse tree attached to it."
    },
    {
        "question": "What is WSJ in the context of computational linguistics?",
        "answer": "WSJ stands for Wall Street Journal, which is one of the very first large scale corpus of American English."
    },
    {
        "question": "What is the purpose of creating a treebank or collection of sentences with trees attached?",
        "answer": "The purpose is to extract the parse trees for each sentence in the text."
    },
    {
        "question": "Identify the components of the sentence 'Peter Vinkin, 61 years old, will join the board as a non-executive director November 29th.'",
        "answer": "The components of the sentence are: noun phrase subject (Peter Vinkin, 61 years old), verb (will join), object (the board), prepositional phrase (as a non-executive director), and time phrase (November 29th)."
    },
    {
        "question": "What is mentioned as a final punctuation in the text?",
        "answer": "full stop"
    },
    {
        "question": "What is one reason why SpaCy is particularly popular in the field of natural language processing?",
        "answer": "SpaCy is particularly popular because it has connections to some of the latest research systems in natural language processing."
    },
    {
        "question": "What is one limitation of NLTK mentioned in the lecture?",
        "answer": "NLTK is more designed for educational purposes and has less direct connection to industrial interfaces."
    },
    {
        "question": "What can you do if there is a feature missing in NLTK?",
        "answer": "You can specify your request on the wanted list and the development team will consider adding it to NLTK."
    },
    {
        "question": "What are some examples of tasks that Gensim is good for?",
        "answer": "Gensim is good for topic modelling and modelling semantics with sentences and words as vectors, such as extracting the topic of a document."
    },
    {
        "question": "What is Gensim specifically good for according to the lecture?",
        "answer": "Topic modelling"
    },
    {
        "question": "What is NLTK particularly good for in terms of learning and university education?",
        "answer": "NLTK is particularly good for teaching natural language processing in universities."
    }
]